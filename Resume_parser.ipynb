{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JibsonJoy/Resume_Extraction/blob/main/Resume_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7BOD3ujMvUd"
      },
      "source": [
        "# Mini_Resume_Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVm5UlESMvUi"
      },
      "source": [
        "# NLP (Natural_Language_Processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymZVJ_pKMvUj"
      },
      "source": [
        "### How to Resume parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG0bBhaYMvUj"
      },
      "source": [
        "## First step\n",
        "### Read the resume and convert to plain text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js-fP-V2MvUk"
      },
      "source": [
        "### For this we have to install and import two modules in python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q6UpwUL7M8XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buXWKuDrMvUk"
      },
      "outputs": [],
      "source": [
        "pip install pdfminer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXRzVsJSMvUn"
      },
      "outputs": [],
      "source": [
        "pip install pdfminer.six\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU4Udp2JMvUn"
      },
      "source": [
        "### Install Doc2text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjLKHxeIMvUo"
      },
      "outputs": [],
      "source": [
        "pip install doc2text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXGxSl19MvUo"
      },
      "source": [
        "#### Extracting text from PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "6Dj2d-GbMvUp"
      },
      "outputs": [],
      "source": [
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHlKKvAFMvUp"
      },
      "source": [
        "### Create a Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLEp3z-mMvUp",
        "outputId": "932fa11e-3241-4871-923c-8bf6b1b71d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  JIBSON JOY \n",
            "\n",
            "AI-ML Engineer  \n",
            "\n",
            "PROFILE \n",
            "\n",
            "WORK EXPERIENCE- FRESHER | 2021 NOV - PRESENT \n",
            "\n",
            "Gender: Male Age: 23 years \n",
            "\n",
            "Date of Birth: 11 Jan 1999 \n",
            "Location : Kottayam,Kerala \n",
            "\n",
            "CONTACT \n",
            "\n",
            "PHONE: +91-9745539271 \n",
            "\n",
            "EMAIL: \n",
            "jibsonjoy4@gmail.com \n",
            "\n",
            "GitHub: \n",
            "https://github.com/JibsonJoy     \n",
            "\n",
            "Linkedln:http://linkedin.com/\n",
            "in/jibson-joy-288150220 \n",
            "\n",
            "Language:  \n",
            "English, Malayalam, Tamil \n",
            "\n",
            "CERTIFICATIONS  \n",
            "\n",
            "NAPT -Big Data ,Data \n",
            "Science,Machine Learning \n",
            "\n",
            "SKILLS \n",
            "\n",
            "Python \n",
            "\n",
            "  NumPy \n",
            "  Matplotlib \n",
            "Scikit-Learn \n",
            " \n",
            "Pandas \n",
            " \n",
            "Flask \n",
            " \n",
            "Python Collections \n",
            " \n",
            "  Visual Studio \n",
            "Lambda \n",
            " \n",
            "\n",
            "About : \n",
            "\n",
            "BIGDATA – DATA SCIENCE – MACHINE LEARNING AND \n",
            "ARTIFICIAL INTELLIGENCE-AWS \n",
            "\n",
            "  B.Com \n",
            "\n",
            "(Computer \n",
            "Student.(GPA : 5.13) \n",
            "\n",
            "Application) \n",
            "\n",
            "Graduate \n",
            "\n",
            "Objective : \n",
            "\n",
            "  To get an opportunity where I can make the best of \n",
            "my potential and contribute to the organization’s \n",
            "growth. \n",
            "\n",
            "  Seeking a position in a company where I can launch \n",
            "\n",
            "my career and build a valuable skill set. \n",
            "\n",
            "  Seeking  a  challenging  position \n",
            "\n",
            "in  a  reputed \n",
            "organization  where  I  can  learn  new  skills,  expand \n",
            "my knowledge, and leverage my learnings. \n",
            "\n",
            " \n",
            "\n",
            "I expect to benefit by inculcating global leadership \n",
            "traits  and \n",
            "leverage  my  ability  to  adapt  and \n",
            "assimilate  knowledge.  I  hope  to  thrive  in  this \n",
            "experimental  system  whilst  relying  on  these  core \n",
            "competencies  to  be  an  active  participant  in  the \n",
            "room. \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f Machine Learning    \n",
            "Regression   \n",
            "Linear Regression \n",
            "Logical Regression \n",
            "Regularization \n",
            "Bagging, Boosting \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Naïve base \n",
            "KNN, SVM \n",
            " \n",
            "  Classification \n",
            "  Unsupervised Leanring \n",
            "K-Means clustering   \n",
            " \n",
            "Statistics \n",
            " \n",
            "\n",
            "Database \n",
            " \n",
            "\n",
            "SQL, MySQL, RDBMS \n",
            "\n",
            "Version Control   \n",
            "  Git \n",
            "\n",
            "Analytical Tools \n",
            "\n",
            "Pig \n",
            "\n",
            "  Hadoop(Eco System) \n",
            " \n",
            "  Hive \n",
            " \n",
            " \n",
            "\n",
            "Sqoop \n",
            "Spark(pyspark,RDD,Data \n",
            "Frame) \n",
            "\n",
            "Operating System \n",
            "\n",
            "Windows and Unix \n",
            "\n",
            "Personal Traits \n",
            "\n",
            "  Self-motivated, \n",
            "\n",
            "optimistic and team \n",
            "player. \n",
            "\n",
            "  Communication skill \n",
            "  Ability to lead a \n",
            "\n",
            "professional team with \n",
            "integrity. \n",
            "\n",
            "  Analytical skills & \n",
            "\n",
            "attention to detail. \n",
            "  Good grasping power \n",
            "and learning skills. \n",
            "  Ability to understand \n",
            "and maintain healthy \n",
            "relationship with \n",
            "colleagues. \n",
            "\n",
            "SKILLS \n",
            "\n",
            "PYTHON\n",
            "MACHINE LEARNING\n",
            "NLP\n",
            "DEEP LEARNING\n",
            "SPARK\n",
            "AWS\n",
            "SQL\n",
            "NEURAL NETWORKS\n",
            "EXCEL\n",
            "BIGDATA\n",
            "HIVE\n",
            "\n",
            "20%\n",
            "\n",
            "50%\n",
            "\n",
            "80%\n",
            "\n",
            "70%\n",
            "\n",
            "75%\n",
            "\n",
            "80%\n",
            "\n",
            "60%\n",
            "\n",
            "80%\n",
            "80%\n",
            "80%\n",
            "\n",
            "80%\n",
            "\n",
            "0.00%\n",
            "\n",
            "25.00% 50.00% 75.00% 100.00%\n",
            "\n",
            "EDUCATION \n",
            "\n",
            "  Bachelor \n",
            "\n",
            "Of \n",
            "\n",
            "Commerce \n",
            "\n",
            "(Computer \n",
            "\n",
            "Application). \n",
            "\n",
            "o  M.C VARGHESE ARTS AND SCIENCE \n",
            "\n",
            "College. \n",
            "\n",
            "o Year:  2017-2021. \n",
            "O Percentage : 60%   \n",
            "\n",
            "  12th – STATE \n",
            "\n",
            "o  NSS HSS HIGHER SECONDARY SCHOOL. \n",
            "o  Year : 2017. \n",
            "o  Percentage : 70%. \n",
            "\n",
            "  10th - STATE \n",
            "\n",
            "o  NSS HSS HIGHER SECONDARY SCHOOL. \n",
            "o  Year: 2015. \n",
            "o  Percentage : 84%. \n",
            "\n",
            "Projects \n",
            "\n",
            "1.  BREAST CANCER PREDICTION MODEL \n",
            "\n",
            "Breast cancer is the most common cancer amongst women in the \n",
            "world. It accounts for 25% of all cancer cases, and affected over \n",
            "2.1 Million people in 2015 alone. It starts when cells in the breast \n",
            "begin to grow out of control. These cells usually form tumors that \n",
            "can be seen via X-ray or felt as lumps in the breast area. \n",
            "\n",
            "2.  PIMA INDIANS DIABETES PREDICTIONS \n",
            "\n",
            "Extra-curricular Achievements \n",
            "\n",
            "The Pima Indians Diabetes Dataset involves predicting the onset \n",
            "of diabetes within 5 years in Pima Indians given medical details. \n",
            "\n",
            "  Sports  Champion  In  10th \n",
            "\n",
            "Link: https://aidiabetics1.herokuapp.com/ \n",
            "\n",
            "Standard. \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f Declaration \n",
            "I declare that the above furnished details regarding my \n",
            "personal and professional background are all true to the best \n",
            "of my knowledge and consciousness. \n",
            "\n",
            "Jibson Joy \n",
            "\n",
            "  First  Prize  In  Biomicron \n",
            "\n",
            "Pharmaceuticals \n",
            "Drawing Competition. \n",
            "\n",
            "  A Grade In \n",
            "\n",
            "VANCHIPATTU (event) \n",
            "27th Revenue District \n",
            "Kalolsavam. \n",
            "\n",
            "  A Grade In \n",
            "\n",
            "VANCHIPATTU \n",
            "(event) 55th Kerala \n",
            "Kalolsavam  (2014-\n",
            "2015). \n",
            "\n",
            "  Member of the \n",
            "\n",
            "organising committee \n",
            "for organizational \n",
            "activities (Annual day,) \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "def text_extract(pdf):\n",
        "    with open(pdf, 'rb') as res:\n",
        "\n",
        "        # iterate over all pages \n",
        "\n",
        "        for page in PDFPage.get_pages(res, caching=True, check_extractable=True):\n",
        "\n",
        "\n",
        "            # creating a resoure manager\n",
        "\n",
        "            res_man = PDFResourceManager()\n",
        "            \n",
        "            # create a file handle\n",
        "            import io\n",
        "            handle_file = io.StringIO()\n",
        "            \n",
        "            # creating a text converter object\n",
        "\n",
        "            converter = TextConverter(\n",
        "                                res_man, \n",
        "                                handle_file, \n",
        "                                codec='utf-8', \n",
        "                                laparams=LAParams()\n",
        "                        )\n",
        "\n",
        "            # creating a page interpreter\n",
        "            \n",
        "            page_interpreter = PDFPageInterpreter(\n",
        "                                res_man, \n",
        "                                converter\n",
        "                            )\n",
        "\n",
        "            # process current page\n",
        "            page_interpreter.process_page(page)\n",
        "            \n",
        "            # extract text\n",
        "            text = handle_file.getvalue()\n",
        "            yield text\n",
        "\n",
        "            # close open handles\n",
        "            converter.close()\n",
        "            handle_file.close()\n",
        "\n",
        "# calling above function and extracting text\n",
        "text=' '\n",
        "file_path=r'/content/drive/MyDrive/jibson_joy (4).pdf'\n",
        "for page in text_extract(file_path):\n",
        "    text += ' ' + page\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvlAxREgMvUq"
      },
      "source": [
        "### Extracting the text from DOC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvI8ZykZMvUq"
      },
      "source": [
        "### Install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6YDjZsjMvUq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "hj5g1PbzMvUq"
      },
      "outputs": [],
      "source": [
        "import docx2txt\n",
        "\n",
        "def extract_text_from_doc(doc_path):\n",
        "    temp = docx2txt.process(doc_path)\n",
        "    text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
        "    return ' '.join(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking the code"
      ],
      "metadata": {
        "id": "3z5DksN7ZFDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "oFj3pXp6MvUr"
      },
      "outputs": [],
      "source": [
        "doc=r'/content/drive/MyDrive/New folder/Arun_Resume_latest.docx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "HfATirvJMvUr"
      },
      "outputs": [],
      "source": [
        "text_from_docx=(extract_text_from_doc(doc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_from_docx"
      ],
      "metadata": {
        "id": "MYQLMNVcbGdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDCnqtBUMvUr"
      },
      "source": [
        "# Pick the Name from the Resume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICBb7TvuMvUr"
      },
      "source": [
        "#### Install spacy  ## Spacy is a type of natural language processing module used for text and language processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxE19TJUMvUr"
      },
      "outputs": [],
      "source": [
        "pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0VNuEyZcMvUs"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_tZxvsrMvUs"
      },
      "source": [
        "# Install vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSpqxf3CMvUs"
      },
      "outputs": [],
      "source": [
        "pip install vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh1iVJ6hMvUs"
      },
      "outputs": [],
      "source": [
        "pip install -U spacy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Phone number"
      ],
      "metadata": {
        "id": "5vWU8SyyQXuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### By the help of Regular Expression"
      ],
      "metadata": {
        "id": "SFrNwSzJR9wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_mobile_number(text):\n",
        "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
        "    \n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "        if len(number) > 10:\n",
        "            print (\"ContactNo:\",'+' + number)\n",
        "        else:\n",
        "          print(\"ContactNo:\",number)"
      ],
      "metadata": {
        "id": "eHCn1pw6PhXs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the code"
      ],
      "metadata": {
        "id": "UFQjPG-vYQmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c='9745539271'"
      ],
      "metadata": {
        "id": "fQ3sTV8EYFvQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_mobile_number(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud3knpEXYJVp",
        "outputId": "a9404e9a-d22f-4bc4-9267-e3fa769e89f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContactNo: 9745539271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting mail"
      ],
      "metadata": {
        "id": "feXap5I1Xmpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_email(email):\n",
        "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
        "    if email:\n",
        "        try:\n",
        "            print (\"EmailID:\",email[0].split()[0].strip(';'))\n",
        "        except IndexError:\n",
        "            return None\n",
        "\n"
      ],
      "metadata": {
        "id": "yaX_8uzUQ82P"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the code"
      ],
      "metadata": {
        "id": "wVd5KqEvYTWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e='jibsonjoy4@gmail.com'"
      ],
      "metadata": {
        "id": "isDUTGWkXyAU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_email(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhYw3YLQbGUS",
        "outputId": "3aa540a0-ada3-460f-8c32-f870dc52bbd2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmailID: jibsonjoy4@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Skills\n"
      ],
      "metadata": {
        "id": "n3YDvh5DbFdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Tokenization & Extraction\n"
      ],
      "metadata": {
        "id": "kbdwmYaZbOg7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HoPLQTRp6n8L"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "def extract_skills(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # removing stop words and implementing word tokenization\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    colnames = ['skill']\n",
        "    # reading the csv file\n",
        "    data = pd.read_clipboard(text) \n",
        "    \n",
        "    # extract values\n",
        "    skills = data.skill.tolist()\n",
        "    print(skills)\n",
        "    skillset = []\n",
        "    \n",
        "    # check for one-grams (example: python)\n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "   \n",
        "    for token in nlp_text:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
        "  "
      ],
      "metadata": {
        "id": "JF5yq5S268gF"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL"
      ],
      "metadata": {
        "id": "uoq4x2VS-nya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract From PDF"
      ],
      "metadata": {
        "id": "eYwy-X6wA1Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_extract(file_path)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eQK6bZa_OSC",
        "outputId": "acba6009-ea55-4748-831c-39cec9ac22e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  JIBSON JOY \n",
            "\n",
            "AI-ML Engineer  \n",
            "\n",
            "PROFILE \n",
            "\n",
            "WORK EXPERIENCE- FRESHER | 2021 NOV - PRESENT \n",
            "\n",
            "Gender: Male Age: 23 years \n",
            "\n",
            "Date of Birth: 11 Jan 1999 \n",
            "Location : Kottayam,Kerala \n",
            "\n",
            "CONTACT \n",
            "\n",
            "PHONE: +91-9745539271 \n",
            "\n",
            "EMAIL: \n",
            "jibsonjoy4@gmail.com \n",
            "\n",
            "GitHub: \n",
            "https://github.com/JibsonJoy     \n",
            "\n",
            "Linkedln:http://linkedin.com/\n",
            "in/jibson-joy-288150220 \n",
            "\n",
            "Language:  \n",
            "English, Malayalam, Tamil \n",
            "\n",
            "CERTIFICATIONS  \n",
            "\n",
            "NAPT -Big Data ,Data \n",
            "Science,Machine Learning \n",
            "\n",
            "SKILLS \n",
            "\n",
            "Python \n",
            "\n",
            "  NumPy \n",
            "  Matplotlib \n",
            "Scikit-Learn \n",
            " \n",
            "Pandas \n",
            " \n",
            "Flask \n",
            " \n",
            "Python Collections \n",
            " \n",
            "  Visual Studio \n",
            "Lambda \n",
            " \n",
            "Regular Expression \n",
            " \n",
            "\n",
            "About : \n",
            "\n",
            "BIGDATA – DATA SCIENCE – MACHINE LEARNING AND \n",
            "ARTIFICIAL INTELLIGENCE-AWS \n",
            "\n",
            "  B.Com \n",
            "\n",
            "(Computer \n",
            "Student.(GPA : 5.13) \n",
            "\n",
            "Application) \n",
            "\n",
            "Graduate \n",
            "\n",
            "Objective : \n",
            "\n",
            "  To get an opportunity where I can make the best of \n",
            "my potential and contribute to the organization’s \n",
            "growth. \n",
            "\n",
            "  Seeking a position in a company where I can launch \n",
            "\n",
            "my career and build a valuable skill set. \n",
            "\n",
            "  Seeking  a  challenging  position \n",
            "\n",
            "in  a  reputed \n",
            "organization  where  I  can  learn  new  skills,  expand \n",
            "my knowledge, and leverage my learnings. \n",
            "\n",
            " \n",
            "\n",
            "I expect to benefit by inculcating global leadership \n",
            "traits  and \n",
            "leverage  my  ability  to  adapt  and \n",
            "assimilate  knowledge.  I  hope  to  thrive  in  this \n",
            "experimental  system  whilst  relying  on  these  core \n",
            "competencies  to  be  an  active  participant  in  the \n",
            "room. \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f Deep Learning \n",
            "\n",
            "  ANN \n",
            "  CNN \n",
            "RNN \n",
            " \n",
            "  OpenCV \n",
            "\n",
            "Machine Learning    \n",
            "Regression   \n",
            "Linear Regression \n",
            "Logical Regression \n",
            "Regularization \n",
            "Bagging, Boosting \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Naïve base \n",
            "KNN, SVM \n",
            " \n",
            "  Classification \n",
            "  Unsupervised Leanring \n",
            "K-Means clustering   \n",
            " \n",
            "Statistics \n",
            " \n",
            "\n",
            "Database \n",
            " \n",
            "\n",
            "SQL, MySQL, RDBMS \n",
            "\n",
            "Version Control   \n",
            "  Git \n",
            "\n",
            "Analytical Tools \n",
            "\n",
            "Pig \n",
            "\n",
            "  Hadoop(Eco System) \n",
            " \n",
            "  Hive \n",
            " \n",
            " \n",
            "\n",
            "Sqoop \n",
            "Spark(pyspark,RDD,Data \n",
            "Frame) \n",
            "\n",
            "Operating System \n",
            "\n",
            "Windows and Unix \n",
            "\n",
            "Personal Traits \n",
            "\n",
            "  Self-motivated, \n",
            "\n",
            "optimistic and team \n",
            "player. \n",
            "\n",
            "  Communication skill \n",
            "  Ability to lead a \n",
            "\n",
            "professional team with \n",
            "integrity. \n",
            "\n",
            "  Analytical skills & \n",
            "\n",
            "attention to detail. \n",
            "  Good grasping power \n",
            "and learning skills. \n",
            "  Ability to understand \n",
            "and maintain healthy \n",
            "relationship with \n",
            "colleagues. \n",
            "\n",
            "Extra-curricular Achievements \n",
            "\n",
            "SKILLS \n",
            "\n",
            "PYTHON\n",
            "MACHINE LEARNING\n",
            "NLP\n",
            "DEEP LEARNING\n",
            "SPARK\n",
            "AWS\n",
            "SQL\n",
            "NEURAL NETWORKS\n",
            "EXCEL\n",
            "BIGDATA\n",
            "HIVE\n",
            "\n",
            "50%\n",
            "\n",
            "80%\n",
            "\n",
            "70%\n",
            "\n",
            "75%\n",
            "\n",
            "80%\n",
            "\n",
            "60%\n",
            "\n",
            "80%\n",
            "80%\n",
            "80%\n",
            "\n",
            "70%\n",
            "\n",
            "80%\n",
            "\n",
            "0.00%\n",
            "\n",
            "25.00% 50.00% 75.00% 100.00%\n",
            "\n",
            "EDUCATION \n",
            "\n",
            "  Bachelor \n",
            "\n",
            "Of \n",
            "\n",
            "Commerce \n",
            "\n",
            "(Computer \n",
            "\n",
            "Application). \n",
            "\n",
            "o  M.C VARGHESE ARTS AND SCIENCE \n",
            "\n",
            "College. \n",
            "\n",
            "o Year:  2017-2021. \n",
            "O Percentage : 60%   \n",
            "\n",
            "  12th – STATE \n",
            "\n",
            "o  NSS HSS HIGHER SECONDARY SCHOOL. \n",
            "o  Year : 2017. \n",
            "o  Percentage : 70%. \n",
            "\n",
            "  10th - STATE \n",
            "\n",
            "o  NSS HSS HIGHER SECONDARY SCHOOL. \n",
            "o  Year: 2015. \n",
            "o  Percentage : 84%. \n",
            "\n",
            "Projects \n",
            "\n",
            "1.  BREAST CANCER PREDICTION MODEL \n",
            "\n",
            "Breast cancer is the most common cancer amongst women in the \n",
            "world. It accounts for 25% of all cancer cases, and affected over \n",
            "2.1 Million people in 2015 alone. It starts when cells in the breast \n",
            "begin to grow out of control. These cells usually form tumors that \n",
            "can be seen via X-ray or felt as lumps in the breast area. \n",
            "\n",
            "2.  PIMA INDIANS DIABETES PREDICTIONS \n",
            "\n",
            "The Pima Indians Diabetes Dataset involves predicting the onset \n",
            "of diabetes within 5 years in Pima Indians given medical details. \n",
            "\n",
            "Link: https://aidiabetics1.herokuapp.com/ \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f Declaration \n",
            "I declare that the above furnished details regarding my \n",
            "personal and professional background are all true to the best \n",
            "of my knowledge and consciousness. \n",
            "\n",
            "Jibson Joy \n",
            "\n",
            "  Sports  Champion  In  10th \n",
            "\n",
            "Standard. \n",
            "\n",
            "  First  Prize  In  Biomicron \n",
            "\n",
            "Pharmaceuticals \n",
            "Drawing Competition. \n",
            "\n",
            "  A Grade In \n",
            "\n",
            "VANCHIPATTU (event) \n",
            "27th Revenue District \n",
            "Kalolsavam. \n",
            "\n",
            "  A Grade In \n",
            "\n",
            "VANCHIPATTU \n",
            "(event) 55th Kerala \n",
            "Kalolsavam  (2014-\n",
            "2015). \n",
            "\n",
            "  Member of the \n",
            "\n",
            "organising committee \n",
            "for organizational \n",
            "activities (Annual day,) \n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mail"
      ],
      "metadata": {
        "id": "QoAsLJgWBj2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_email(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMhpbgeTBcev",
        "outputId": "e39ec4a0-d4c0-4167-df7c-79c5c6c2aceb"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmailID: jibsonjoy4@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_email(text_from_docx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0T_5QKn1PP0",
        "outputId": "3e5c34cc-6d1f-432b-d2a7-adf6507edb91"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmailID: Arunvignesh377@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phone_Number"
      ],
      "metadata": {
        "id": "F6_onsrDBqLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_mobile_number(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lfuGnRVBogn",
        "outputId": "d14a3b42-1717-4d8e-f0d3-aec7b104c090"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContactNo: +91974553927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_mobile_number(text_from_docx)"
      ],
      "metadata": {
        "id": "XSeEWIpDB0UW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1928d61-41b1-42f0-e2ca-5abed717ff8e"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContactNo: +918714135828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name"
      ],
      "metadata": {
        "id": "ElVQ0wFcHCa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "def extract_the_name(res_text):\n",
        "  nlp_text=nlp(res_text)\n",
        "  pattern = [[{\"LIKE_EMAIL\": True}], [{\"POS\": \"PROPN\"}]]\n",
        "  matcher.add(\"My_Pattern\",pattern)\n",
        "  matches = matcher(nlp_text)\n",
        "  for match_id,start,end in matches:\n",
        "    print(nlp_text[start:3])\n",
        "    break"
      ],
      "metadata": {
        "id": "tquY96b0uXt0"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name Extraction"
      ],
      "metadata": {
        "id": "33TZeldHy3kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_the_name(text_from_docx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brFn1--Uucx7",
        "outputId": "14972519-0821-4ed2-97bb-d3349faf3c73"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arun Vignesh M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_the_name(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUU1lE1H03QC",
        "outputId": "1e7eeeae-ad77-4d3f-9030-a82da415fd91"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JIBSON JOY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "Zm7BfK5NAmOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert PDF to Text\n",
        "\n",
        "text_extract(file_path)\n",
        "\n",
        "# file_path = user defined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GpXE-7BBB-P",
        "outputId": "7b4d8fdd-dfc9-44f1-d528-99d7e270bbb1"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object text_extract at 0x7f32b9e5a1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Docx File into Text\n",
        "\n",
        "extract_text_from_doc(doc)\n",
        "\n",
        "# doc = path of the docx file = user defined"
      ],
      "metadata": {
        "id": "rTlPDd3yBO64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name \n",
        "# Email\n",
        "# Contact NO:\n",
        "# Skills"
      ],
      "metadata": {
        "id": "Wy8BlmyrAoP4"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function of Each one"
      ],
      "metadata": {
        "id": "oxuL-4RWB9lH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_the_name\n",
        "\n",
        "extract_email\n",
        "\n",
        "extract_mobile_number\n",
        "\n",
        "extract_skills"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNowphgsAyXK",
        "outputId": "401c0061-faa6-47f5-eda4-d35365ce2a3d"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.extract_skills(resume_text)>"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHwUUHN0BAk8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0eb98743bfad9c0d53c30530ba0e13e617439b85f83655d9d8d6ecadf551e6c4"
      }
    },
    "colab": {
      "name": "Resume_parser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}